import os
import google.generativeai as genai
import streamlit as st
import docx
import time
from google.generativeai.types import HarmCategory, HarmBlockThreshold

# ‚ö†Ô∏è Import ‡πÑ‡∏ü‡∏•‡πå prompt.py
from prompt import PROMPT_CED

# üîê ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ API Key ‡∏à‡∏≤‡∏Å Streamlit Secrets
try:
    api_key = st.secrets["GEMINI_API_KEY"]
except KeyError:
    st.error("API Key not found. Please add 'GEMINI_API_KEY' to your Streamlit secrets.")
    st.stop()

genai.configure(api_key=api_key)

# ‚öôÔ∏è ‡∏Å‡∏≤‡∏£‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤ Model
generation_config = {
    "temperature": 0.01,
    "top_p": 0.95,
    "top_k": 64,
    "max_output_tokens": 1024,
    "response_mime_type": "text/plain",
}

# üîê ‡∏ï‡∏±‡πâ‡∏á‡∏Ñ‡πà‡∏≤‡∏Ñ‡∏ß‡∏≤‡∏°‡∏õ‡∏•‡∏≠‡∏î‡∏†‡∏±‡∏¢‡∏Ç‡∏≠‡∏á‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤
SAFETY_SETTINGS = {
    HarmCategory.HARM_CATEGORY_HARASSMENT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_HATE_SPEECH: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: HarmBlockThreshold.BLOCK_NONE,
    HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: HarmBlockThreshold.BLOCK_NONE,
}

# üîç ‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÇ‡∏°‡πÄ‡∏î‡∏• Gemini
model = genai.GenerativeModel(
    model_name="gemini-2.0-flash",
    safety_settings=SAFETY_SETTINGS,
    generation_config=generation_config,
)

# ‡∏ü‡∏±‡∏á‡∏Å‡πå‡∏ä‡∏±‡∏ô‡∏≠‡πà‡∏≤‡∏ô‡πÑ‡∏ü‡∏•‡πå Word (.docx)
def read_docx(file_path):
    """Reads text from a .docx file."""
    doc = docx.Document(file_path)
    full_text = [para.text.strip() for para in doc.paragraphs if para.text.strip()]
    return '\n'.join(full_text)

@st.cache_data
def load_dataset():
    """Loads and caches data only from the .docx dataset."""
    file_path = "DatasetEPW.docx"
    if os.path.exists(file_path):
        try:
            text = read_docx(file_path)
            return text, True, None
        except Exception as e:
            return "", False, str(e)
    else:
        return "", False, "File not found."

# üîß Sidebar: ‡∏õ‡∏∏‡πà‡∏° Clear ‡πÅ‡∏•‡∏∞ Restore
def clear_history():
    st.session_state["full_history"] = st.session_state["messages"][:]
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏ó‡πà‡∏≤‡∏ô‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏à‡∏¥‡∏ï‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏£‡∏π"}
    ]
    st.rerun()

def restore_history():
    if "full_history" in st.session_state:
        st.session_state["messages"] = st.session_state["full_history"][:]
    st.rerun()

with st.sidebar:
    st.header("‡∏ï‡∏±‡∏ß‡πÄ‡∏•‡∏∑‡∏≠‡∏Å‡πÅ‡∏ä‡∏ó‡∏ö‡∏≠‡∏ó")
    col1, col2 = st.columns(2)
    with col1:
        if st.button("üßπ ‡∏•‡πâ‡∏≤‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥", use_container_width=True):
            clear_history()
    with col2:
        if st.button("‚Ü©Ô∏è ‡πÄ‡∏£‡∏µ‡∏¢‡∏Å‡∏Ñ‡∏∑‡∏ô‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥", use_container_width=True):
            restore_history()

    # ‡πÇ‡∏´‡∏•‡∏î dataset
    dataset_text, dataset_loaded, dataset_error = load_dataset()
    st.subheader("‡∏™‡∏ñ‡∏≤‡∏ô‡∏∞‡∏Å‡∏≤‡∏£‡πÇ‡∏´‡∏•‡∏î‡πÑ‡∏ü‡∏•‡πå")
    if dataset_loaded:
        st.success("‚úÖ Dataset (.docx) loaded successfully")
    else:
        st.error(f"‚ùå Could not load dataset: {dataset_error}")

# üßæ ‡∏ä‡∏∑‡πà‡∏≠‡πÅ‡∏≠‡∏õ
st.title("üí¨ ‡∏¢‡∏¥‡∏ô‡∏î‡∏µ‡∏ï‡πâ‡∏≠‡∏ô‡∏£‡∏±‡∏ö‡πÄ‡∏Ç‡πâ‡∏≤‡∏™‡∏π‡πà Chatbot ‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤‡∏à‡∏¥‡∏ï‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏£‡∏π")

# ‡πÄ‡∏£‡∏¥‡πà‡∏°‡∏ï‡πâ‡∏ô session state
if "messages" not in st.session_state:
    st.session_state["messages"] = [
        {"role": "model", "content": "‡∏ó‡πà‡∏≤‡∏ô‡∏™‡∏ô‡πÉ‡∏à‡∏™‡∏≠‡∏ö‡∏ñ‡∏≤‡∏°‡∏Ç‡πâ‡∏≠‡∏°‡∏π‡∏•‡πÄ‡∏Å‡∏µ‡πà‡∏¢‡∏ß‡∏Å‡∏±‡∏ö‡πÄ‡∏ô‡∏∑‡πâ‡∏≠‡∏´‡∏≤‡∏Ç‡∏≠‡∏á‡∏£‡∏≤‡∏¢‡∏ß‡∏¥‡∏ä‡∏≤ ‡πÄ‡∏ä‡πà‡∏ô ‡∏Ñ‡∏ß‡∏≤‡∏°‡∏´‡∏°‡∏≤‡∏¢ ‡∏Ñ‡∏ß‡∏≤‡∏°‡πÄ‡∏õ‡πá‡∏ô‡∏°‡∏≤ ‡∏´‡∏£‡∏∑‡∏≠‡∏õ‡∏£‡∏∞‡πÇ‡∏¢‡∏ä‡∏ô‡πå‡∏Ç‡∏≠‡∏á‡∏à‡∏¥‡∏ï‡∏ß‡∏¥‡∏ó‡∏¢‡∏≤‡∏™‡∏≥‡∏´‡∏£‡∏±‡∏ö‡∏Ñ‡∏£‡∏π"}
    ]
if "full_history" not in st.session_state:
    st.session_state["full_history"] = []

# ‡πÅ‡∏™‡∏î‡∏á‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏Å‡∏≤‡∏£‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
for msg in st.session_state["messages"]:
    st.chat_message(msg["role"]).markdown(msg["content"])

# ‡πÄ‡∏°‡∏∑‡πà‡∏≠‡∏ú‡∏π‡πâ‡πÉ‡∏ä‡πâ‡∏ñ‡∏≤‡∏°
if prompt := st.chat_input():
    st.session_state["messages"].append({"role": "user", "content": prompt})
    st.chat_message("user").markdown(prompt)

    if not dataset_loaded:
        error_msg = "‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡πÑ‡∏°‡πà‡∏û‡∏ö dataset ‡πÑ‡∏°‡πà‡∏™‡∏≤‡∏°‡∏≤‡∏£‡∏ñ‡πÉ‡∏´‡πâ‡∏Ñ‡∏≥‡∏ï‡∏≠‡∏ö‡πÑ‡∏î‡πâ‡πÉ‡∏ô‡∏Ç‡∏ì‡∏∞‡∏ô‡∏µ‡πâ"
        st.chat_message("model").markdown(error_msg)
        st.session_state["messages"].append({"role": "model", "content": error_msg})
    else:
        # ‡πÉ‡∏™‡πà PROMPT + Dataset + ‡∏Ñ‡∏≥‡∏ñ‡∏≤‡∏° ‡∏•‡∏á‡πÑ‡∏õ‡∏û‡∏£‡πâ‡∏≠‡∏°‡∏Å‡∏±‡∏ô
        messages_for_gemini = [
            {"role": "user", "parts": [
                {"text": PROMPT_CED},
                {"text": f"--- Dataset ---\n{dataset_text}"},
                {"text": f"--- User Question ---\n{prompt}"}
            ]}
        ]

        # ‡πÄ‡∏û‡∏¥‡πà‡∏°‡∏õ‡∏£‡∏∞‡∏ß‡∏±‡∏ï‡∏¥‡∏™‡∏ô‡∏ó‡∏ô‡∏≤
        for msg in st.session_state["messages"]:
            messages_for_gemini.append({"role": msg["role"], "parts": [{"text": msg["content"]}]})

        # ‡∏™‡πà‡∏á‡πÉ‡∏´‡πâ‡πÇ‡∏°‡πÄ‡∏î‡∏•
        with st.chat_message("model"):
            try:
                message_placeholder = st.empty()
                dots = ["", ".", "..", "..."]
                for i in range(5):
                    message_placeholder.markdown(f"‡∏Å‡∏≥‡∏•‡∏±‡∏á‡∏Ñ‡∏¥‡∏î... {dots[i % 4]}")
                    time.sleep(0.3)

                response = model.generate_content(messages_for_gemini, stream=True)

                full_response = ""
                for chunk in response:
                    full_response += chunk.text
                    time.sleep(0.05)
                    message_placeholder.markdown(full_response + "‚ñå")
                message_placeholder.markdown(full_response)

                st.session_state["messages"].append({"role": "model", "content": full_response})
            except Exception as e:
                error_msg = f"‡∏Ç‡∏≠‡∏≠‡∏†‡∏±‡∏¢‡∏Ñ‡πà‡∏∞ ‡∏°‡∏µ‡∏Ç‡πâ‡∏≠‡∏ú‡∏¥‡∏î‡∏û‡∏•‡∏≤‡∏î: {e}"
                st.error(error_msg)
                st.session_state["messages"].append({"role": "model", "content": error_msg})
